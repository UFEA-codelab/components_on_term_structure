{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOBJ0VVzjVfFS+XY7BjH8Rj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaealways/components_on_term_structure/blob/main/term_structure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data"
      ],
      "metadata": {
        "id": "WCHSsaAgtU1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기간구조 데이터에서 유의미한 정보를 추출하려면, 먼저 데이터에 대해 살펴볼 필요가 있습니다."
      ],
      "metadata": {
        "id": "fO_wTb0etDT1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHdzgZsRuCxw"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "# matplotlib.use('TkAgg')\n",
        "import seaborn as sns\n",
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.decomposition import PCA\n",
        "#mpl.rcParams['figure.dpi'] = 200"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "HTML(\"<style>.container {width:98% !important; }</style>\")\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "import seaborn as sns\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "sns.set_palette(\"Set2\")"
      ],
      "metadata": {
        "id": "WuXq7GzDueky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터를 호출하는 fredapi를 설치합니다."
      ],
      "metadata": {
        "id": "LlhDrHcm-yvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fredapi"
      ],
      "metadata": {
        "id": "TMl2fKguujP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fredapi import Fred\n",
        "fred = Fred(api_key='cd9a27c9afcd4ee82ec0be135fb8b223')\n",
        "\n",
        "# get data\n",
        "startDate = '2019-09-01'\n",
        "endDate = '2020-09-01'\n",
        "df = []\n",
        "ids = ['DGS{}'.format(i) for i in [1,2,5,7,10,20,30]]\n",
        "for s in ids:\n",
        "    df.append(fred.get_series(s, observation_start=startDate,observation_end=endDate)/100)\n",
        "\n",
        "df = pd.concat(df,axis=1)\n",
        "df.columns = ids\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "M8t1-rMtuloh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시간이 지남에 따라 기간구조가 어떤 모습을 보이는지 시각화합니다."
      ],
      "metadata": {
        "id": "Dr9G2KDO--Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# curve dynamic\n",
        "fig,(ax,ax2)=plt.subplots(nrows=2,ncols=1,figsize=(10,5*2))\n",
        "df.plot(grid=True, title='US Treasury Constant Maturity Rate', ax=ax)\n",
        "df.index.intersection([datetime(2019,9,1),datetime(2019,3,31),datetime(2020,9,1)])\n",
        "x = df.loc[df.index.intersection([datetime(2019,9,1),datetime(2019,3,31),datetime(2020,9,1)])]\n",
        "x.index = [t.date() for t in x.index]\n",
        "ax2.plot(x.T.index,x.T,marker='*')\n",
        "ax2.legend(x.index)\n",
        "ax2.grid(True)\n",
        "ax2.set_title('Term structure on different dates')\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "cFvNZ0i4u4zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Normality Test"
      ],
      "metadata": {
        "id": "2SE268tErZG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "PCA는 인풋 데이터가 정규분포를 따른다는 가정하에, 그 논리를 전개하기 때문에 기간구조 데이터가 정규분포를 따르는지 검증하는 절차가 필요합니다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b_xLhU0RSYxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = df.hist(bins=30, sharex=True)"
      ],
      "metadata": {
        "id": "715qoLnqSo_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시각화를 진행했을 때, 대부분의 데이터가 multimodal 분포를 따르는 것으로 확인되었는데, 보다 정확한 판별을 위해 정규성 검정을 진행합니다."
      ],
      "metadata": {
        "id": "xYavAetejvh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 Q-Q Plot"
      ],
      "metadata": {
        "id": "ZZLurM4Sre_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-Q plot을 통해 살펴보면 다음과 같습니다."
      ],
      "metadata": {
        "id": "bnYv_pmsj-Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import probplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, axes = plt.subplots(7, 2, figsize=(12,30))\n",
        "for i in range(7):\n",
        "    axes[i][0].boxplot(df.iloc[:,i])\n",
        "    probplot(df.iloc[:,i], plot=axes[i][1])\n",
        "plt.axis(\"equal\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0dDIYsmNkIRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.2 Shapiro-Test"
      ],
      "metadata": {
        "id": "p4nY3W4Rrjhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터가 정규성을 만족한다는 귀무가설을 통해, p-value를 반환해서 정규성을 판단하고자 합니다."
      ],
      "metadata": {
        "id": "nQ48wYMDmhYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import shapiro\n",
        "\n",
        "list_shapiro_test=[]\n",
        "for i in range(7):\n",
        "    list_shapiro_test.append(shapiro(df.iloc[:,i]))\n",
        "list_shapiro_test"
      ],
      "metadata": {
        "id": "DPnhYAxomwI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 데이터의 p-value가 유의미하게 낮게 나와 기각역에 속한다고 볼 수 있습니다. 즉 정규성을 만족하지 못합니다."
      ],
      "metadata": {
        "id": "1dThZ137nan6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. PCA"
      ],
      "metadata": {
        "id": "wuGFDTqErpBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Principal Component Analysis로 기간구조를 분해하기 위해 [Aleksei Malinovskii, \"Term Structure Analysis using PCA\", 2022](https://fam.tuwien.ac.at/~sgerhold/pub_files/sem21/s_malinovskii.pdf) 논문을 참고했습니다. 요약본은 제가 작성한 [아티클](https://github.com/jaealways/jaealways.github.io/blob/master/_posts/2023-08-11-Term-Structure-Analysis-using-PCA.md)을 참고하시기 바랍니다."
      ],
      "metadata": {
        "id": "3Bqege8_St1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Principal Components Modification"
      ],
      "metadata": {
        "id": "yRtNu8l8rvcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 코드는 논문의 저자가 pca 오픈소스를 그대로 차용하지 않고, term structure 계산에 맞게 변형한 부분입니다.</br></br>\n",
        "대표적으로 위의 **논문** 3.4.2의 loading matrix V에서 pc1과 pc2의 값을 변형시켜주는 것이 있습니다. code에선 self.adjust_sign에서 이를 판별합니다.\n",
        "\n",
        "PC1의 경우 항상 양의 load를 갖다보니, np.sign 메소드를 통해 항상 양의 값을 유지하도록 로직을 변경했습니다.\n",
        "PC2의 경우 \"The loading increases from a negative value at the short end to a positive value at\n",
        "the long end.\" 부분에 의해 -np.sign을 곱해준 것 같은데, 아직 정확히 이해하진 못했습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "yTIhNk7e_CNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "class PCABase(object):\n",
        "    def __init__(self, X, adjust_sign=True):\n",
        "        self.X = X\n",
        "        self.n_features = X.shape[1]\n",
        "        self.dates = X.index\n",
        "        self.Xc = self.X - self.X.mean() # centered\n",
        "        self.pc_names = lambda n: ['PC' + str(i) for i in np.arange(1, n +1)]\n",
        "        self.adjust_sign = adjust_sign\n",
        "\n",
        "\n",
        "    def pca(self, n_pc=None):\n",
        "        '''\n",
        "        fit pca model\n",
        "        n_pc: number of pcs to fit, take total feature numbers if not\n",
        "        ,→ specified\n",
        "        '''\n",
        "        if n_pc:\n",
        "            model = PCA(n_components=n_pc).fit(self.Xc)\n",
        "        else:\n",
        "            model = PCA().fit(self.Xc)\n",
        "        return model\n",
        "\n",
        "    def cps(self):\n",
        "        '''\n",
        "        loading matrix => principal axes in feature space\n",
        "        '''\n",
        "        cps = self.pca().components_.T\n",
        "        cps = self.to_df_pc(cps, is_loading=True)\n",
        "        if self.adjust_sign:\n",
        "            cps.loc[:, 'PC1'] = np.sign(cps.loc[:, 'PC1'].values[0]) * cps.loc[:, 'PC1']\n",
        "            cps.loc[:, 'PC2'] = -np.sign(cps.loc[:, 'PC2'].values[0]) * cps.loc[:, 'PC2']\n",
        "        return cps\n",
        "\n",
        "    def cumsum_expvar_ratio(self):\n",
        "        var_exp = self.pca().explained_variance_ratio_\n",
        "        var_exp_cumsum = np.cumsum(var_exp)\n",
        "        return var_exp, var_exp_cumsum\n",
        "\n",
        "    def scores(self):\n",
        "        '''\n",
        "        PC scores:\n",
        "        '''\n",
        "        scores = self.pca().transform(self.Xc)\n",
        "        scores = self.to_df_pc(scores)\n",
        "        if self.adjust_sign:\n",
        "            cps = self.cps()\n",
        "        scores.loc[:, 'PC1'] = np.sign(cps.loc[:, 'PC1'].values[0]) * scores.loc[:, 'PC1']\n",
        "        scores.loc[:, 'PC2'] = -np.sign(cps.loc[:, 'PC2'].values[0]) * scores.loc[:, 'PC2']\n",
        "        return scores\n",
        "\n",
        "    def scores2(self):\n",
        "        '''\n",
        "        equivalent to the sklearn transform function\n",
        "        '''\n",
        "        scores = self.Xc.dot(self.cps())\n",
        "        scores = self.to_df_pc(scores)\n",
        "\n",
        "        if self.adjust_sign:\n",
        "            cps = self.cps()\n",
        "            scores.loc[:, 'PC1'] = np.sign(cps.loc[:, 'PC1'].values[0]) * scores.loc[:, 'PC1']\n",
        "            scores.loc[:, 'PC2'] = -np.sign(cps.loc[:, 'PC2'].values[0]) * scores.loc[:, 'PC2']\n",
        "        return scores\n",
        "\n",
        "    def x_projected(self, p, centered=False):\n",
        "        xp = self.scores().iloc[:, 0:p].dot(self.cps().T.iloc[0:p, :])\n",
        "        if not centered:\n",
        "            xp = xp + self.X.mean()\n",
        "        return xp\n",
        "\n",
        "    def residuals(self, p):\n",
        "        residuals = self.X - self.x_projected(p, centered=False)\n",
        "        return residuals\n",
        "\n",
        "    def covX(self):\n",
        "        return self.X.cov()\n",
        "\n",
        "    def eigenv(self):\n",
        "        eig_vals, eig_vecs = np.linalg.eig(self.covX())\n",
        "        return eig_vals, eig_vecs\n",
        "\n",
        "    def to_df_pc(self, data, is_loading=False):\n",
        "        cols = self.pc_names(self.n_features)\n",
        "        idx = self.X.columns if is_loading else self.dates\n",
        "        return pd.DataFrame(data, columns=cols, index=idx)"
      ],
      "metadata": {
        "id": "ogKB6v1Hw8ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 PCA experiment"
      ],
      "metadata": {
        "id": "ShCfa5Mqn5EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# contruct pca object\n",
        "pcab = PCABase(df)\n",
        "\n",
        "# loading matrix (direction may change but doesn't matter)\n",
        "V = pd.DataFrame(pcab.pca().components_,index=pcab.pc_names(pcab.n_features),columns=ids)\n",
        "V.T.iloc[:,0:3].plot(figsize=(10,5),kind='bar')\n",
        "pcab.cps()\n",
        "\n",
        "# resconstruction and residuals\n",
        "r = 'DGS10'\n",
        "fig,(ax,ax2)=plt.subplots(figsize=(8,4*2),ncols=1,nrows=2)\n",
        "ax.plot(pcab.x_projected(1)[r])\n",
        "ax.plot(pcab.x_projected(2)[r])\n",
        "ax.plot(pcab.x_projected(3)[r])\n",
        "ax.legend(['Reconstructed (PC1)','Reconstructed (PC1,PC2)','Reconstructed (PC1,PC2,PC3)'])\n",
        "ax.set_title('{} reconstructed by PCs'.format(r))\n",
        "\n",
        "ax2.plot(pcab.residuals(1)[r])\n",
        "ax2.plot(pcab.residuals(2)[r])\n",
        "ax2.plot(pcab.residuals(3)[r])\n",
        "ax2.legend(['Residual (PC1)','Residual (PC1,PC2)','Residual (PC1,PC2,PC3)'])\n",
        "ax2.set_title('{} residuals from reconstructed by PCs'.format(r))\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "0_L8OOTlu41y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resconstruction and residuals\n",
        "r = 'DGS30'\n",
        "fig,(ax,ax2)=plt.subplots(figsize=(8,4*2),ncols=1,nrows=2)\n",
        "ax.plot(pcab.x_projected(1)[r])\n",
        "ax.plot(pcab.x_projected(2)[r])\n",
        "ax.plot(pcab.x_projected(3)[r])\n",
        "ax.legend(['Reconstructed (PC1)','Reconstructed (PC1,PC2)','Reconstructed (PC1,PC2,PC3)'])\n",
        "ax.set_title('{} reconstructed by PCs'.format(r))\n",
        "\n",
        "ax2.plot(pcab.residuals(1)[r])\n",
        "ax2.plot(pcab.residuals(2)[r])\n",
        "ax2.plot(pcab.residuals(3)[r])\n",
        "ax2.legend(['Residual (PC1)','Residual (PC1,PC2)','Residual (PC1,PC2,PC3)'])\n",
        "ax2.set_title('{} residuals from reconstructed by PCs'.format(r))\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "8R5iBEZxwxqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PC Scores\n",
        "fig,(ax1,ax2,ax3)=plt.subplots(nrows=3,ncols=1,figsize=(8,3*3))\n",
        "l1=ax1.plot(pcab.scores()['PC1'])\n",
        "ax12 = ax1.twinx()\n",
        "l2=ax12.plot(pcab.X['DGS10'],color='orange')\n",
        "ax1.tick_params('x',rotation=30)\n",
        "ax1.legend(l1+l2,['PC1 score','DGS10'])\n",
        "ax1.set_ylabel('score')\n",
        "ax12.set_ylabel('DGS10')\n",
        "\n",
        "l1=ax2.plot(pcab.scores()['PC2'])\n",
        "ax22 = ax2.twinx()\n",
        "l2=ax22.plot(pcab.X['DGS10']-pcab.X['DGS2'],color='orange')\n",
        "ax2.tick_params('x',rotation=30)\n",
        "ax2.legend(l1+l2,['PC2 score','DGS10-DGS2'],loc='best')\n",
        "ax2.set_ylabel('score')\n",
        "ax22.set_ylabel('DGS10-DGS2')\n",
        "\n",
        "l1=ax3.plot(pcab.scores()['PC3'])\n",
        "ax32 = ax3.twinx()\n",
        "l2=ax32.plot(pcab.X['DGS30']-2*pcab.X['DGS10']+pcab.X['DGS5'],color='orange')\n",
        "ax3.tick_params('x',rotation=30)\n",
        "ax3.legend(l1+l2,['PC3 score','DGS30-2DGS10+DGS5'],loc='best')\n",
        "ax3.set_ylabel('score')\n",
        "ax32.set_ylabel('DGS30-2DGS10+DGS5')\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "aZ-MYTkDw1EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PC\n",
        "fig,ax=plt.subplots(figsize=(10,5))\n",
        "l1=pcab.scores().iloc[:,0:3].plot(ax=ax)\n",
        "ax.grid(True)\n",
        "ax.set_title('Evolution of PCA Factors 1,2,3')\n",
        "\n",
        "# PCA-explained variance ratio\n",
        "\n",
        "fig,(ax,ax2) = plt.subplots(figsize=(6*2, 4),ncols=2,nrows=1)\n",
        "ax.bar(range(pcab.n_features), pcab.cumsum_expvar_ratio()[0], alpha=0.5, align='center')\n",
        "ax.set_ylabel('Explained variance percentage')\n",
        "ax.set_xlabel('Principal components')\n",
        "ax.set_title('Individual PC explained variance percentage')\n",
        "\n",
        "ax2.bar(range(pcab.n_features), pcab.cumsum_expvar_ratio()[1], alpha=0.5, align='center')\n",
        "ax2.set_ylabel('Explained variance percentage')\n",
        "ax2.set_xlabel('Principal components')\n",
        "ax2.set_title('Cumulative PC explained variance percentage')\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "nv_5iX3xw3qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. SVD"
      ],
      "metadata": {
        "id": "LbTRtChFqK9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.ICA"
      ],
      "metadata": {
        "id": "L9Z23AE3r6mM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ICA를 금융데이터에 적용하기 위해 [A First Application of Independent Component Analysis to Extracting\n",
        "Structure from Stock Returns](https://archive.nyu.edu/bitstream/2451/14180/1/Is-97-22.pdf) 논문을 참조했습니다. 요약본은 제가 쓴 [다음 아티클](https://github.com/jaealways/jaealways.github.io/blob/master/_posts/2023-08-15-A-First-Application-of-Independent-Component-Analysis-to-Extracting-Structure-from-Stock-Returns.md)을 참고하시기 바랍니다."
      ],
      "metadata": {
        "id": "-rzn1AoStioy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import FastICA\n",
        "ICA = FastICA(n_components=20, random_state=0)\n",
        "X_transformed = ICA.fit_transform(df)\n",
        "A_ = ICA.mixing_.T\n",
        "\n",
        "plt.figure(figsize = (12, 2))\n",
        "plt.plot(df.iloc[:,0], label=\"data\")\n",
        "plt.plot(np.dot(X_transformed[:,0], A_), label=\"reconstruct\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "gJkzH7Dc16cB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}