{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN0DzPNQ+gaXRDs+2kJe3Zo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaealways/term_structure_component/blob/main/term_structure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA vs 다른 모델\n",
        "원래 과제가 [해당논문](https://fam.tuwien.ac.at/~sgerhold/pub_files/sem21/s_malinovskii.pdf)을 바탕으로 구현을 해보는 것이었는데, 논문에서 언급되었던 ICA나 SVD 같은 모델들을 추가로 비교해서 PCA를 벤치마크로 각 성분들이 어떤 특징을 보이는지 비교하면 좋겠다고 생각했습니다.\n",
        "\n",
        "우선 PCA는 위의 논문 뒷부분의 소스코드를 그대로 차용해서 변형이 있는 부분에 대해 이해하고, ICA 등 다른 모델에 이를 적용하려 했습니다."
      ],
      "metadata": {
        "id": "r2rAZUfV967i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. PCA"
      ],
      "metadata": {
        "id": "WCHSsaAgtU1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHdzgZsRuCxw"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "# matplotlib.use('TkAgg')\n",
        "import seaborn as sns\n",
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.decomposition import PCA\n",
        "#mpl.rcParams['figure.dpi'] = 200"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "HTML(\"<style>.container {width:98% !important; }</style>\")\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "import seaborn as sns\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "sns.set_palette(\"Set2\")"
      ],
      "metadata": {
        "id": "WuXq7GzDueky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터를 호출하는 fredapi를 설치합니다."
      ],
      "metadata": {
        "id": "LlhDrHcm-yvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fredapi"
      ],
      "metadata": {
        "id": "TMl2fKguujP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fredapi import Fred\n",
        "fred = Fred(api_key='cd9a27c9afcd4ee82ec0be135fb8b223')\n",
        "\n",
        "# get data\n",
        "startDate = '2019-09-01'\n",
        "endDate = '2020-09-01'\n",
        "df = []\n",
        "ids = ['DGS{}'.format(i) for i in [1,2,5,7,10,20,30]]\n",
        "for s in ids:\n",
        "    df.append(fred.get_series(s, observation_start=startDate,observation_end=endDate)/100)\n",
        "\n",
        "df = pd.concat(df,axis=1)\n",
        "df.columns = ids\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "M8t1-rMtuloh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "논문과 같이 커브를 그리는 코드입니다."
      ],
      "metadata": {
        "id": "Dr9G2KDO--Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# curve dynamic\n",
        "fig,(ax,ax2)=plt.subplots(nrows=2,ncols=1,figsize=(10,5*2))\n",
        "df.plot(grid=True, title='US Treasury Constant Maturity Rate', ax=ax)\n",
        "x = df.loc[df.index.intersection([datetime(2019,9,1),datetime(2019,12,15),datetime(2020,3,30)])]\n",
        "x.index = [t.date() for t in x.index]\n",
        "ax2.plot(x.T.index,x.T,marker='*')\n",
        "ax2.legend(x.index)\n",
        "ax2.grid(True)\n",
        "ax2.set_title('Term structure on different dates')\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "cFvNZ0i4u4zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 코드는 논문의 저자가 pca 오픈소스를 그대로 차용하지 않고, term structure 계산에 맞게 변형한 부분입니다.</br></br>\n",
        "대표적으로 논문 3.4.2의 loading m,atrix V에서 pc1과 pc2의 값을 변형시켜주는 것이 있습니다. code에선 self.adjust_sign에서 이를 판별합니다.\n",
        "\n",
        "PC1의 경우 항상 양의 load를 갖다보니, np.sign 메소드를 통해 항상 양의 값을 유지하도록 로직을 변경했습니다.\n",
        "PC2의 경우 \"The loading increases from a negative value at the short end to a positive value at\n",
        "the long end.\" 부분에 의해 -np.sign을 곱해준 것 같은데, 아직 정확히 이해하진 못했습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "yTIhNk7e_CNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "class PCABase(object):\n",
        "    def __init__(self, X, adjust_sign=True):\n",
        "        self.X = X\n",
        "        self.n_features = X.shape[1]\n",
        "        self.dates = X.index\n",
        "        self.Xc = self.X - self.X.mean() # centered\n",
        "        self.pc_names = lambda n: ['PC' + str(i) for i in np.arange(1, n +1)]\n",
        "        self.adjust_sign = adjust_sign\n",
        "\n",
        "\n",
        "    def pca(self, n_pc=None):\n",
        "        '''\n",
        "        fit pca model\n",
        "        n_pc: number of pcs to fit, take total feature numbers if not\n",
        "        ,→ specified\n",
        "        '''\n",
        "        if n_pc:\n",
        "            model = PCA(n_components=n_pc).fit(self.Xc)\n",
        "        else:\n",
        "            model = PCA().fit(self.Xc)\n",
        "        return model\n",
        "\n",
        "    def cps(self):\n",
        "        '''\n",
        "        loading matrix => principal axes in feature space\n",
        "        '''\n",
        "        cps = self.pca().components_.T\n",
        "        cps = self.to_df_pc(cps, is_loading=True)\n",
        "        if self.adjust_sign:\n",
        "            cps.loc[:, 'PC1'] = np.sign(cps.loc[:, 'PC1'].values[0]) * cps.loc[:, 'PC1']\n",
        "            cps.loc[:, 'PC2'] = -np.sign(cps.loc[:, 'PC2'].values[0]) * cps.loc[:, 'PC2']\n",
        "        return cps\n",
        "\n",
        "    def cumsum_expvar_ratio(self):\n",
        "        var_exp = self.pca().explained_variance_ratio_\n",
        "        var_exp_cumsum = np.cumsum(var_exp)\n",
        "        return var_exp, var_exp_cumsum\n",
        "\n",
        "    def scores(self):\n",
        "        '''\n",
        "        PC scores:\n",
        "        '''\n",
        "        scores = self.pca().transform(self.Xc)\n",
        "        scores = self.to_df_pc(scores)\n",
        "        if self.adjust_sign:\n",
        "            cps = self.cps()\n",
        "        scores.loc[:, 'PC1'] = np.sign(cps.loc[:, 'PC1'].values[0]) * scores.loc[:, 'PC1']\n",
        "        scores.loc[:, 'PC2'] = -np.sign(cps.loc[:, 'PC2'].values[0]) * scores.loc[:, 'PC2']\n",
        "        return scores\n",
        "\n",
        "    def scores2(self):\n",
        "        '''\n",
        "        equivalent to the sklearn transform function\n",
        "        '''\n",
        "        scores = self.Xc.dot(self.cps())\n",
        "        scores = self.to_df_pc(scores)\n",
        "\n",
        "        if self.adjust_sign:\n",
        "            cps = self.cps()\n",
        "            scores.loc[:, 'PC1'] = np.sign(cps.loc[:, 'PC1'].values[0]) * scores.loc[:, 'PC1']\n",
        "            scores.loc[:, 'PC2'] = -np.sign(cps.loc[:, 'PC2'].values[0]) * scores.loc[:, 'PC2']\n",
        "        return scores\n",
        "\n",
        "    def x_projected(self, p, centered=False):\n",
        "        xp = self.scores().iloc[:, 0:p].dot(self.cps().T.iloc[0:p, :])\n",
        "        if not centered:\n",
        "            xp = xp + self.X.mean()\n",
        "        return xp\n",
        "\n",
        "    def residuals(self, p):\n",
        "        residuals = self.X - self.x_projected(p, centered=False)\n",
        "        return residuals\n",
        "\n",
        "    def covX(self):\n",
        "        return self.X.cov()\n",
        "\n",
        "    def eigenv(self):\n",
        "        eig_vals, eig_vecs = np.linalg.eig(self.covX())\n",
        "        return eig_vals, eig_vecs\n",
        "\n",
        "    def to_df_pc(self, data, is_loading=False):\n",
        "        cols = self.pc_names(self.n_features)\n",
        "        idx = self.X.columns if is_loading else self.dates\n",
        "        return pd.DataFrame(data, columns=cols, index=idx)"
      ],
      "metadata": {
        "id": "ogKB6v1Hw8ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contruct pca object\n",
        "pcab = PCABase(df)\n",
        "\n",
        "# loading matrix (direction may change but doesn't matter)\n",
        "V = pd.DataFrame(pcab.pca().components_,index=pcab.pc_names(pcab.n_features),columns=ids)\n",
        "V.T.iloc[:,0:3].plot(figsize=(10,5),kind='bar')\n",
        "pcab.cps()\n",
        "\n",
        "# resconstruction and residuals\n",
        "r = 'DGS10'\n",
        "fig,(ax,ax2)=plt.subplots(figsize=(8,4*2),ncols=1,nrows=2)\n",
        "ax.plot(pcab.x_projected(1)[r])\n",
        "ax.plot(pcab.x_projected(2)[r])\n",
        "ax.plot(pcab.x_projected(3)[r])\n",
        "ax.legend(['Reconstructed (PC1)','Reconstructed (PC1,PC2)','Reconstructed (PC1,PC2,PC3)'])\n",
        "ax.set_title('{} reconstructed by PCs'.format(r))\n",
        "\n",
        "ax2.plot(pcab.residuals(1)[r])\n",
        "ax2.plot(pcab.residuals(2)[r])\n",
        "ax2.plot(pcab.residuals(3)[r])\n",
        "ax2.legend(['Residual (PC1)','Residual (PC1,PC2)','Residual (PC1,PC2,PC3)'])\n",
        "ax2.set_title('{} residuals from reconstructed by PCs'.format(r))\n",
        "fig.tight_layout()\n",
        "\n"
      ],
      "metadata": {
        "id": "0_L8OOTlu41y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resconstruction and residuals\n",
        "r = 'DGS30'\n",
        "fig,(ax,ax2)=plt.subplots(figsize=(8,4*2),ncols=1,nrows=2)\n",
        "ax.plot(pcab.x_projected(1)[r])\n",
        "ax.plot(pcab.x_projected(2)[r])\n",
        "ax.plot(pcab.x_projected(3)[r])\n",
        "ax.legend(['Reconstructed (PC1)','Reconstructed (PC1,PC2)','Reconstructed (PC1,PC2,PC3)'])\n",
        "ax.set_title('{} reconstructed by PCs'.format(r))\n",
        "\n",
        "ax2.plot(pcab.residuals(1)[r])\n",
        "ax2.plot(pcab.residuals(2)[r])\n",
        "ax2.plot(pcab.residuals(3)[r])\n",
        "ax2.legend(['Residual (PC1)','Residual (PC1,PC2)','Residual (PC1,PC2,PC3)'])\n",
        "ax2.set_title('{} residuals from reconstructed by PCs'.format(r))\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "8R5iBEZxwxqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PC Scores\n",
        "fig,(ax1,ax2,ax3)=plt.subplots(nrows=3,ncols=1,figsize=(8,3*3))\n",
        "l1=ax1.plot(pcab.scores()['PC1'])\n",
        "ax12 = ax1.twinx()\n",
        "l2=ax12.plot(pcab.X['DGS10'],color='orange')\n",
        "ax1.tick_params('x',rotation=30)\n",
        "ax1.legend(l1+l2,['PC1 score','DGS10'])\n",
        "ax1.set_ylabel('score')\n",
        "ax12.set_ylabel('DGS10')\n",
        "\n",
        "l1=ax2.plot(pcab.scores()['PC2'])\n",
        "ax22 = ax2.twinx()\n",
        "l2=ax22.plot(pcab.X['DGS10']-pcab.X['DGS2'],color='orange')\n",
        "ax2.tick_params('x',rotation=30)\n",
        "ax2.legend(l1+l2,['PC2 score','DGS10-DGS2'],loc='best')\n",
        "ax2.set_ylabel('score')\n",
        "ax22.set_ylabel('DGS10-DGS2')\n",
        "\n",
        "l1=ax3.plot(pcab.scores()['PC3'])\n",
        "ax32 = ax3.twinx()\n",
        "l2=ax32.plot(pcab.X['DGS30']-2*pcab.X['DGS10']+pcab.X['DGS5'],color='orange')\n",
        "ax3.tick_params('x',rotation=30)\n",
        "ax3.legend(l1+l2,['PC3 score','DGS30-2DGS10+DGS5'],loc='best')\n",
        "ax3.set_ylabel('score')\n",
        "ax32.set_ylabel('DGS30-2DGS10+DGS5')\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "aZ-MYTkDw1EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PC\n",
        "fig,ax=plt.subplots(figsize=(10,5))\n",
        "l1=pcab.scores().iloc[:,0:3].plot(ax=ax)\n",
        "ax.grid(True)\n",
        "ax.set_title('Evolution of PCA Factors 1,2,3')\n",
        "\n",
        "# PCA-explained variance ratio\n",
        "\n",
        "fig,(ax,ax2) = plt.subplots(figsize=(6*2, 4),ncols=2,nrows=1)\n",
        "ax.bar(range(pcab.n_features), pcab.cumsum_expvar_ratio()[0], alpha=0.5, align='center')\n",
        "ax.set_ylabel('Explained variance percentage')\n",
        "ax.set_xlabel('Principal components')\n",
        "ax.set_title('Individual PC explained variance percentage')\n",
        "\n",
        "ax2.bar(range(pcab.n_features), pcab.cumsum_expvar_ratio()[1], alpha=0.5, align='center')\n",
        "ax2.set_ylabel('Explained variance percentage')\n",
        "ax2.set_xlabel('Principal components')\n",
        "ax2.set_title('Cumulative PC explained variance percentage')\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "nv_5iX3xw3qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ICA"
      ],
      "metadata": {
        "id": "puGhRskTtfcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "원래 ICA, SVD 코드까지 구현해서 벤치마크와 비교하면 좋겠다고 생각했는데 시간관계상 우선 PCA까지 제출하겠습니다.\n",
        "\n",
        "\n",
        "ICA와 관련해서 제가 읽은 논문은 [A First Application of Independent Component Analysis to Extracting\n",
        "Structure from Stock Returns](https://archive.nyu.edu/bitstream/2451/14180/1/Is-97-22.pdf)라는 논문으로, 아직 완성되진 않았지만 제 [요약본](https://github.com/jaealways/jaealways.github.io/blob/master/_posts/2023-08-15-A-First-Application-of-Independent-Component-Analysis-to-Extracting-Structure-from-Stock-Returns.md) 함께 올려드립니다."
      ],
      "metadata": {
        "id": "-rzn1AoStioy"
      }
    }
  ]
}